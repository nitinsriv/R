vif(model_37)
# remove DistanceFromHome4.7 since it became insignificant
model_38 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
JobRoleResearch.Director + JobRoleResearch.Scientist + JobRoleSales.Executive +
MaritalStatusSingle +  NumCompaniesWorked5 + NumCompaniesWorked7 + NumCompaniesWorked9 +
TrainingTimesLastYear6 + PercentSalaryHike23. + TotalWorkingYears2.6 + YearsAtCompany12.14 +
YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. + DistanceFromHome15.19 +
Age33.38 + Age39.41 + Age42.45 + Age46.50 + Age50.57 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_38)
vif(model_38)
# remove NumCompaniesWorked9 since it became insignificant
model_39 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
JobRoleResearch.Director + JobRoleResearch.Scientist + JobRoleSales.Executive +
MaritalStatusSingle +  NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 +
PercentSalaryHike23. + TotalWorkingYears2.6 + YearsAtCompany12.14 +
YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. + DistanceFromHome15.19 +
Age33.38 + Age39.41 + Age42.45 + Age46.50 + Age50.57 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_39)
vif(model_39)
# remove TotalWorkingYears2.6 since it is related to YearsAtCompany6.11
model_40 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
JobRoleResearch.Director + JobRoleResearch.Scientist + JobRoleSales.Executive +
MaritalStatusSingle +  NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 +
PercentSalaryHike23. + YearsAtCompany12.14 +
YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. + DistanceFromHome15.19 +
Age33.38 + Age39.41 + Age42.45 + Age46.50 + Age50.57 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_40)
vif(model_40)
# remove JobRoleResearch.Director since it became insignificant
model_41 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
JobRoleResearch.Scientist + JobRoleSales.Executive + MaritalStatusSingle +
NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 + PercentSalaryHike23. +
YearsAtCompany12.14 + YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. +
DistanceFromHome15.19 + Age33.38 + Age39.41 + Age42.45 + Age46.50 + Age50.57 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_41)
vif(model_41)
# remove JobRoleSales.Executive since it became insignificant
model_42 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
JobRoleResearch.Scientist + MaritalStatusSingle +
NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 + PercentSalaryHike23. +
YearsAtCompany12.14 + YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. +
DistanceFromHome15.19 + Age33.38 + Age39.41 + Age42.45 + Age46.50 + Age50.57 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_42)
vif(model_42)
# remove JobRoleResearch.Scientist since it became insignificant
model_43 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
MaritalStatusSingle + NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 + PercentSalaryHike23. +
YearsAtCompany12.14 + YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. +
DistanceFromHome15.19 + Age33.38 + Age39.41 + Age42.45 + Age46.50 + Age50.57 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_43)
vif(model_43)
# remove YearsAtCompany12.14 since it became insignificant
model_44 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
MaritalStatusSingle + NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 + PercentSalaryHike23. +
YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. +
DistanceFromHome15.19 + Age33.38 + Age39.41 + Age42.45 + Age46.50 + Age50.57 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_44)
vif(model_44)
# remove Age39.41 since it is related to Age33.38
model_45 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
MaritalStatusSingle + NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 + PercentSalaryHike23. +
YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. +
DistanceFromHome15.19 + Age33.38 + Age42.45 + Age46.50 + Age50.57 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_45)
vif(model_45)
# remove Age50.57 since it is related to Age33.38
model_46 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
MaritalStatusSingle + NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 + PercentSalaryHike23. +
YearsAtCompany6.11 + YearsSinceLastPromotion3.7 + YearsWithCurrManager12. +
DistanceFromHome15.19 + Age33.38 + Age42.45 + Age46.50 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_46)
vif(model_46)
# remove YearsSinceLastPromotion3.7 since it became insignificant
model_47 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development + JobLevel5 +
MaritalStatusSingle + NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 + PercentSalaryHike23. +
YearsAtCompany6.11 + YearsWithCurrManager12. +
DistanceFromHome15.19 + Age33.38 + Age42.45 + Age46.50 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_47)
vif(model_47)
# remove JobLevel5 since it became insignificant
model_48 <- glm(Attrition ~ EnvironmentSatisfaction4 + JobSatisfaction4 + WorkLifeBalance3 +
BusinessTravelTravel_Frequently + DepartmentResearch...Development +
MaritalStatusSingle + NumCompaniesWorked5 + NumCompaniesWorked7 + TrainingTimesLastYear6 + PercentSalaryHike23. +
YearsAtCompany6.11 + YearsWithCurrManager12. +
DistanceFromHome15.19 + Age33.38 + Age42.45 + Age46.50 + Age58. +
ActualWorkingHours , family = "binomial", data = train)
summary(model_48)
vif(model_48)
# predicted probabilities of Churn 1 for test data
test_pred = predict(final_model, test[,-1],type = "response")
summary(test_pred)
test$prob <- test_pred
final_model <- model_48
# predicted probabilities of Churn 1 for test data
test_pred = predict(final_model, test[,-1],type = "response")
summary(test_pred)
test$prob <- test_pred
test_pred
test_pred_attrition_50 <- factor(ifelse(test_pred >= 0.50, 1,0))
# confusion matrix
test_conf_50 <- confusionMatrix(test_pred_attrition_50, test$Attrition, positive = "1")
# Sensitivity : 0.15455
# Specificity : 0.98224
# Accuracy : 0.8411
test_conf_50
test_conf_50 <- confusionMatrix(test_pred_attrition_50, test$Attrition, positive = "1")
test_conf_50 <- confusionMatrix(test_pred_attrition_50, test$Attrition)
View(test_conf_50)
test_conf_50 <- confusionMatrix(test_pred_attrition_50, test$Attrition, positive = "1")
test_pred_attrition_50
test_pred_attrition_50 <- factor(ifelse(test_pred >= 0.50, "Yes","No"))
test_conf_50 <- confusionMatrix(test_pred_attrition_50, test$Attrition, positive = "Yes")
test_pred_attrition_50 <- ifelse(test_pred >= 0.50, 1,0)
test_conf_50 <- confusionMatrix(test_pred_attrition_50, test$Attrition, positive = "1")
test_conf_50 <- confusionMatrix(test_pred_attrition_50, test$Attrition, positive = '1')
test_conf_50 <- caret::confusionMatrix(test_pred_attrition_50, test$Attrition, positive = '1')
test_conf_50
test_conf_50 <- InformationValue::confusionMatrix(test_pred,test$Attrition)
test_conf_50
test_conf_50 <- caret::confusionMatrix(test_pred_attrition_50, test$Attrition, positive = '1')
test_conf_50 <- caret::confusionMatrix(test_pred_attrition_50, test$Attrition, positive = '1')
test_conf_50
# compute optimal probalility cutoff for better model reliability
perform_fn <- function(cutoff)
{
pred_attrition <- factor(ifelse(test_pred >= cutoff, 1,0))
conf <- confusionMatrix(pred_attrition, test$Attrition, positive = "1")
acc <- conf$overall[1]
sens <- conf$byClass[1]
spec <- conf$byClass[2]
out <- t(as.matrix(c(sens, spec, acc)))
colnames(out) <- c("sensitivity", "specificity", "accuracy")
return(out)
}
# Creating cutoff values from 0.003575 to 0.812100 for plotting and initiallizing a matrix of 100 X 3.
prob_seq = seq(.01,.85,length=100)
OUT = matrix(0,100,3)
for(i in 1:100)
{
OUT[i,] = perform_fn(prob_seq[i])
}
# plot sensitivity , specificity and accuracy with different values of probability
plot(prob_seq, OUT[,1],xlab="Cutoff",ylab="Value",cex.lab=1.5,cex.axis=1.5,ylim=c(0,1),type="l",lwd=2,axes=FALSE,col=2)
axis(1,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
axis(2,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
lines(prob_seq,OUT[,2],col="darkgreen",lwd=2)
lines(prob_seq,OUT[,3],col=4,lwd=2)
box()
legend(0,.50,col=c(2,"darkgreen",4,"darkred"),lwd=c(2,2,2,2),c("Sensitivity","Specificity","Accuracy"))
# compute optimal probalility cutoff for better model reliability
perform_fn <- function(cutoff)
{
pred_attrition <- factor(ifelse(test_pred >= cutoff, 1,0))
conf <- caret::confusionMatrix(pred_attrition, test$Attrition, positive = "1")
acc <- conf$overall[1]
sens <- conf$byClass[1]
spec <- conf$byClass[2]
out <- t(as.matrix(c(sens, spec, acc)))
colnames(out) <- c("sensitivity", "specificity", "accuracy")
return(out)
}
# Creating cutoff values from 0.003575 to 0.812100 for plotting and initiallizing a matrix of 100 X 3.
prob_seq = seq(.01,.85,length=100)
OUT = matrix(0,100,3)
for(i in 1:100)
{
OUT[i,] = perform_fn(prob_seq[i])
}
# plot sensitivity , specificity and accuracy with different values of probability
plot(prob_seq, OUT[,1],xlab="Cutoff",ylab="Value",cex.lab=1.5,cex.axis=1.5,ylim=c(0,1),type="l",lwd=2,axes=FALSE,col=2)
axis(1,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
axis(2,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
lines(prob_seq,OUT[,2],col="darkgreen",lwd=2)
lines(prob_seq,OUT[,3],col=4,lwd=2)
box()
cutoff <- prob_seq[which(abs(OUT[,1]-OUT[,2])<0.01)]
test_pred_attrition <- factor(ifelse(test_pred >= 0.17, 1,0))
test_conf <- caret::confusionMatrix(test_pred_attrition, test$Attrition, positive = "1")
test_conf
ks_stat(test$Attrition,test_pred_attrition)
ks_plot(test$Attrition,test_pred_attrition)
summary(model_48)
summary(emp_ef)
library(dplyr)
library(ggplot2)
library(cowplot)
library(corrplot)
library("MASS")
library(car)
library(caret)
library(InformationValue)
library(ROCR)
# read all data into R
emp_survey <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\employee_survey_data.csv", stringsAsFactors=F)
gen_data <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\general_data.csv", stringsAsFactors=F)
in_time <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\in_time.csv", stringsAsFactors=F,header=F)
mgr_survey <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\manager_survey_data.csv", stringsAsFactors=F)
out_time <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\out_time.csv", stringsAsFactors=F,header=F)
# add IN to dates of first row for in_time and OUT to first row of out_time
in_char <- "IN"
in_time[1,] <- sapply(in_time[1,], function(x) x <- paste(x,in_char,sep="_"))
out_char <- "OUT"
out_time[1,] <- sapply(out_time[1,], function(x) x <- paste(x,out_char,sep="_"))
# make first row as table columns for in_time and out_time
colnames(in_time) <- in_time[1,]
in_time <- in_time[-1,]
colnames(out_time) <- out_time[1,]
out_time <- out_time[-1,]
# in_time and out_time: assumption first column is EmployeeId
# assign coumnname 'EmployeeID' to first column for in_time and out_time dataframe
# number of unique values in 'EmployeeId column' for both dataframes is 4410
colnames(in_time)[1] <- 'EmployeeID'
colnames(out_time)[1] <- 'EmployeeID'
setdiff(in_time$EmployeeID,out_time$EmployeeID)
# find and remove all IN_TIME and OUT_TIME columns which have all values as NA
in_time_na <- as.data.frame(sapply(in_time, function(x) sum(is.na(x))))
na_cols_in_time <- which(in_time_na == 4410)
in_time <- in_time[,-na_cols_in_time]
out_time_na <- as.data.frame(sapply(out_time, function(x) sum(is.na(x))))
na_cols_out_time <- which(out_time_na == 4410)
out_time <- out_time[,-na_cols_out_time]
diff_hours <- as.numeric(in_time$EmployeeID)
for (i in 2:250){
act_workHours <- as.numeric(difftime(strptime(out_time[,i],"%Y-%m-%d %H:%M:%S"),
strptime(in_time[,i],"%Y-%m-%d %H:%M:%S")))
diff_hours <- cbind(diff_hours,act_workHours)
}
diff_hours <- as.data.frame(diff_hours)
colnames(diff_hours)[1] <- 'EmployeeID'
diff_hours$ActualWorkingHours <- apply(diff_hours[,-1],1,function(x) mean(x,na.rm=TRUE))
actual_workHours <- diff_hours[,c('EmployeeID','ActualWorkingHours')]
# notice number of rows in EmployeeID column for dataframes  - 4410.
length(unique(emp_survey$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(gen_data$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(mgr_survey$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(in_time$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(out_time$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
# check if all values of employeeID are same inall dataframes
setdiff(emp_survey$EmployeeID,gen_data$EmployeeID) # Identical EmployeeID across these datasets
setdiff(gen_data$EmployeeID,in_time$EmployeeID) # Identical customerID across these datasets
setdiff(in_time$EmployeeID,mgr_survey$EmployeeID) # Identical customerID across these datasets
setdiff(mgr_survey$EmployeeID,out_time$EmployeeID) # Identical customerID across these datasets
# merge into single dataframe, joined by EmployeeID values.
emp_ef <- merge(emp_survey,gen_data,by="EmployeeID", all = F)
emp_ef <- merge(emp_ef,mgr_survey,by="EmployeeID", all = F)
# emp_ef <- merge(emp_ef,in_time,by="EmployeeID", all = F)
# emp_ef <- merge(emp_ef,out_time,by="EmployeeID", all = F)
# remove EmployeeCount, Over18 and StandardHours column since they hold same value for all rows.
unique(emp_ef$EmployeeCount)
unique(emp_ef$Over18)
unique(emp_ef$StandardHours)
emp_ef <- emp_ef[,-c(12,19,21)]
# summary of emp_ef
summary(emp_ef)
str(emp_ef)
library(dplyr)
library(ggplot2)
library(cowplot)
library(corrplot)
library("MASS")
library(car)
library(caret)
library(InformationValue)
library(ROCR)
# read all data into R
emp_survey <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\employee_survey_data.csv")
gen_data <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\general_data.csv")
in_time <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\in_time.csv", stringsAsFactors=F,header=F)
mgr_survey <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\manager_survey_data.csv")
out_time <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\out_time.csv", stringsAsFactors=F,header=F)
# add IN to dates of first row for in_time and OUT to first row of out_time
in_char <- "IN"
in_time[1,] <- sapply(in_time[1,], function(x) x <- paste(x,in_char,sep="_"))
out_char <- "OUT"
out_time[1,] <- sapply(out_time[1,], function(x) x <- paste(x,out_char,sep="_"))
# make first row as table columns for in_time and out_time
colnames(in_time) <- in_time[1,]
in_time <- in_time[-1,]
colnames(out_time) <- out_time[1,]
out_time <- out_time[-1,]
# in_time and out_time: assumption first column is EmployeeId
# assign coumnname 'EmployeeID' to first column for in_time and out_time dataframe
# number of unique values in 'EmployeeId column' for both dataframes is 4410
colnames(in_time)[1] <- 'EmployeeID'
colnames(out_time)[1] <- 'EmployeeID'
setdiff(in_time$EmployeeID,out_time$EmployeeID)
# find and remove all IN_TIME and OUT_TIME columns which have all values as NA
in_time_na <- as.data.frame(sapply(in_time, function(x) sum(is.na(x))))
na_cols_in_time <- which(in_time_na == 4410)
in_time <- in_time[,-na_cols_in_time]
out_time_na <- as.data.frame(sapply(out_time, function(x) sum(is.na(x))))
na_cols_out_time <- which(out_time_na == 4410)
out_time <- out_time[,-na_cols_out_time]
diff_hours <- as.numeric(in_time$EmployeeID)
for (i in 2:250){
act_workHours <- as.numeric(difftime(strptime(out_time[,i],"%Y-%m-%d %H:%M:%S"),
strptime(in_time[,i],"%Y-%m-%d %H:%M:%S")))
diff_hours <- cbind(diff_hours,act_workHours)
}
diff_hours <- as.data.frame(diff_hours)
colnames(diff_hours)[1] <- 'EmployeeID'
diff_hours$ActualWorkingHours <- apply(diff_hours[,-1],1,function(x) mean(x,na.rm=TRUE))
actual_workHours <- diff_hours[,c('EmployeeID','ActualWorkingHours')]
# notice number of rows in EmployeeID column for dataframes  - 4410.
length(unique(emp_survey$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(gen_data$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(mgr_survey$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(in_time$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(out_time$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
# check if all values of employeeID are same inall dataframes
setdiff(emp_survey$EmployeeID,gen_data$EmployeeID) # Identical EmployeeID across these datasets
setdiff(gen_data$EmployeeID,in_time$EmployeeID) # Identical customerID across these datasets
setdiff(in_time$EmployeeID,mgr_survey$EmployeeID) # Identical customerID across these datasets
setdiff(mgr_survey$EmployeeID,out_time$EmployeeID) # Identical customerID across these datasets
# merge into single dataframe, joined by EmployeeID values.
emp_ef <- merge(emp_survey,gen_data,by="EmployeeID", all = F)
emp_ef <- merge(emp_ef,mgr_survey,by="EmployeeID", all = F)
# emp_ef <- merge(emp_ef,in_time,by="EmployeeID", all = F)
# emp_ef <- merge(emp_ef,out_time,by="EmployeeID", all = F)
# remove EmployeeCount, Over18 and StandardHours column since they hold same value for all rows.
unique(emp_ef$EmployeeCount)
unique(emp_ef$Over18)
unique(emp_ef$StandardHours)
emp_ef <- emp_ef[,-c(12,19,21)]
# summary of emp_ef
summary(emp_ef)
# structure of emp_ef
str(emp_ef)
IV <- create_infotables(emp_ef, y="Attrition", bins=10, parallel=FALSE)
emp_ef$Attrition <- as.numeric(emp_ef$Attrition)
IV <- create_infotables(emp_ef, y="Attrition", bins=10, parallel=FALSE)
View(emp_ef)
library(dplyr)
library(ggplot2)
library(cowplot)
library(corrplot)
library("MASS")
library(car)
library(caret)
library(InformationValue)
library(ROCR)
# read all data into R
emp_survey <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\employee_survey_data.csv")
gen_data <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\general_data.csv")
in_time <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\in_time.csv", stringsAsFactors=F,header=F)
mgr_survey <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\manager_survey_data.csv")
out_time <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\out_time.csv", stringsAsFactors=F,header=F)
# add IN to dates of first row for in_time and OUT to first row of out_time
in_char <- "IN"
in_time[1,] <- sapply(in_time[1,], function(x) x <- paste(x,in_char,sep="_"))
out_char <- "OUT"
out_time[1,] <- sapply(out_time[1,], function(x) x <- paste(x,out_char,sep="_"))
# make first row as table columns for in_time and out_time
colnames(in_time) <- in_time[1,]
in_time <- in_time[-1,]
colnames(out_time) <- out_time[1,]
out_time <- out_time[-1,]
# in_time and out_time: assumption first column is EmployeeId
# assign coumnname 'EmployeeID' to first column for in_time and out_time dataframe
# number of unique values in 'EmployeeId column' for both dataframes is 4410
colnames(in_time)[1] <- 'EmployeeID'
colnames(out_time)[1] <- 'EmployeeID'
setdiff(in_time$EmployeeID,out_time$EmployeeID)
# find and remove all IN_TIME and OUT_TIME columns which have all values as NA
in_time_na <- as.data.frame(sapply(in_time, function(x) sum(is.na(x))))
na_cols_in_time <- which(in_time_na == 4410)
in_time <- in_time[,-na_cols_in_time]
out_time_na <- as.data.frame(sapply(out_time, function(x) sum(is.na(x))))
na_cols_out_time <- which(out_time_na == 4410)
out_time <- out_time[,-na_cols_out_time]
diff_hours <- as.numeric(in_time$EmployeeID)
for (i in 2:250){
act_workHours <- as.numeric(difftime(strptime(out_time[,i],"%Y-%m-%d %H:%M:%S"),
strptime(in_time[,i],"%Y-%m-%d %H:%M:%S")))
diff_hours <- cbind(diff_hours,act_workHours)
}
diff_hours <- as.data.frame(diff_hours)
colnames(diff_hours)[1] <- 'EmployeeID'
diff_hours$ActualWorkingHours <- apply(diff_hours[,-1],1,function(x) mean(x,na.rm=TRUE))
actual_workHours <- diff_hours[,c('EmployeeID','ActualWorkingHours')]
# notice number of rows in EmployeeID column for dataframes  - 4410.
length(unique(emp_survey$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(gen_data$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(mgr_survey$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(in_time$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(out_time$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
# check if all values of employeeID are same inall dataframes
setdiff(emp_survey$EmployeeID,gen_data$EmployeeID) # Identical EmployeeID across these datasets
setdiff(gen_data$EmployeeID,in_time$EmployeeID) # Identical customerID across these datasets
setdiff(in_time$EmployeeID,mgr_survey$EmployeeID) # Identical customerID across these datasets
setdiff(mgr_survey$EmployeeID,out_time$EmployeeID) # Identical customerID across these datasets
# merge into single dataframe, joined by EmployeeID values.
emp_ef <- merge(emp_survey,gen_data,by="EmployeeID", all = F)
emp_ef <- merge(emp_ef,mgr_survey,by="EmployeeID", all = F)
# emp_ef <- merge(emp_ef,in_time,by="EmployeeID", all = F)
# emp_ef <- merge(emp_ef,out_time,by="EmployeeID", all = F)
# remove EmployeeCount, Over18 and StandardHours column since they hold same value for all rows.
unique(emp_ef$EmployeeCount)
unique(emp_ef$Over18)
unique(emp_ef$StandardHours)
emp_ef <- emp_ef[,-c(12,19,21)]
# summary of emp_ef
summary(emp_ef)
# structure of emp_ef
str(emp_ef)
View(emp_ef)
levels(emp_ef$Attrition) <-c(1,0)
emp_ef$Attrition <- as.numeric(levels(emp_ef$Attrition))[emp_ef$Attrition]
IV <- create_infotables(emp_ef, y="Attrition", bins=10, parallel=FALSE)
IV
IV <- create_infotables(emp_ef[,-1], y="Attrition", bins=10, parallel=FALSE)
IV
levels(emp_ef$Attrition) <-c(0,1)
emp_ef$Attrition <- as.numeric(levels(emp_ef$Attrition))[emp_ef$Attrition]
IV <- create_infotables(emp_ef[,-1], y="Attrition", bins=10, parallel=FALSE)
library(dplyr)
library(ggplot2)
library(cowplot)
library(corrplot)
library("MASS")
library(car)
library(caret)
library(InformationValue)
library(ROCR)
# read all data into R
emp_survey <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\employee_survey_data.csv")
gen_data <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\general_data.csv")
in_time <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\in_time.csv", stringsAsFactors=F,header=F)
mgr_survey <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\manager_survey_data.csv")
out_time <- read.csv("C:\\IIITB\\HR Analytics Case Study\\PA-I_Case_Study_HR_Analytics\\out_time.csv", stringsAsFactors=F,header=F)
# add IN to dates of first row for in_time and OUT to first row of out_time
in_char <- "IN"
in_time[1,] <- sapply(in_time[1,], function(x) x <- paste(x,in_char,sep="_"))
out_char <- "OUT"
out_time[1,] <- sapply(out_time[1,], function(x) x <- paste(x,out_char,sep="_"))
# make first row as table columns for in_time and out_time
colnames(in_time) <- in_time[1,]
in_time <- in_time[-1,]
colnames(out_time) <- out_time[1,]
out_time <- out_time[-1,]
# in_time and out_time: assumption first column is EmployeeId
# assign coumnname 'EmployeeID' to first column for in_time and out_time dataframe
# number of unique values in 'EmployeeId column' for both dataframes is 4410
colnames(in_time)[1] <- 'EmployeeID'
colnames(out_time)[1] <- 'EmployeeID'
setdiff(in_time$EmployeeID,out_time$EmployeeID)
# find and remove all IN_TIME and OUT_TIME columns which have all values as NA
in_time_na <- as.data.frame(sapply(in_time, function(x) sum(is.na(x))))
na_cols_in_time <- which(in_time_na == 4410)
in_time <- in_time[,-na_cols_in_time]
out_time_na <- as.data.frame(sapply(out_time, function(x) sum(is.na(x))))
na_cols_out_time <- which(out_time_na == 4410)
out_time <- out_time[,-na_cols_out_time]
diff_hours <- as.numeric(in_time$EmployeeID)
for (i in 2:250){
act_workHours <- as.numeric(difftime(strptime(out_time[,i],"%Y-%m-%d %H:%M:%S"),
strptime(in_time[,i],"%Y-%m-%d %H:%M:%S")))
diff_hours <- cbind(diff_hours,act_workHours)
}
diff_hours <- as.data.frame(diff_hours)
colnames(diff_hours)[1] <- 'EmployeeID'
diff_hours$ActualWorkingHours <- apply(diff_hours[,-1],1,function(x) mean(x,na.rm=TRUE))
actual_workHours <- diff_hours[,c('EmployeeID','ActualWorkingHours')]
# notice number of rows in EmployeeID column for dataframes  - 4410.
length(unique(emp_survey$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(gen_data$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(mgr_survey$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(in_time$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
length(unique(out_time$EmployeeID)) # confirm EmployeeID can be a key to merge different dataframe
# check if all values of employeeID are same inall dataframes
setdiff(emp_survey$EmployeeID,gen_data$EmployeeID) # Identical EmployeeID across these datasets
setdiff(gen_data$EmployeeID,in_time$EmployeeID) # Identical customerID across these datasets
setdiff(in_time$EmployeeID,mgr_survey$EmployeeID) # Identical customerID across these datasets
setdiff(mgr_survey$EmployeeID,out_time$EmployeeID) # Identical customerID across these datasets
# merge into single dataframe, joined by EmployeeID values.
emp_ef <- merge(emp_survey,gen_data,by="EmployeeID", all = F)
emp_ef <- merge(emp_ef,mgr_survey,by="EmployeeID", all = F)
# emp_ef <- merge(emp_ef,in_time,by="EmployeeID", all = F)
# emp_ef <- merge(emp_ef,out_time,by="EmployeeID", all = F)
# remove EmployeeCount, Over18 and StandardHours column since they hold same value for all rows.
unique(emp_ef$EmployeeCount)
unique(emp_ef$Over18)
unique(emp_ef$StandardHours)
emp_ef <- emp_ef[,-c(12,19,21)]
# summary of emp_ef
summary(emp_ef)
# structure of emp_ef
str(emp_ef)
########################## Missing Value Imputation ##########################
# find columns containing NA with number of NA
sapply(emp_ef, function(x) sum(is.na(x)))
library(Information)
